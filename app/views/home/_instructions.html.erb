<p>This is a quick synopsis of the indexing tasks that are done on a regular basis. They should be executed from the
	command line when in the <span class="code">~/www/catalog</span> folder. There are other rake tasks
	that can be done. See <span class="code">rake -T</span> for more info.
</p>
<h3>Initial indexing</h3>
<p>Use these steps when you get a brand new archive to index.</p>
<ol>
	<li>Update rdf/sitemap.yml
		<p>
			A line needs to be put into the sitemap file for each archive. The format is:<br /><span class="code">"archive_name": ["archive/folder", num_docs_to_process_at_once]</span>.<br />
			The line can be put in any section, but the archives are roughly ordered from small to large. If the archive has either a lot of documents, or each document has a large
			amount of text, it should be placed lower in the file. The <span class="code">archive_name</span> must EXACTLY match the archive in the RDF. You cannot mix
			archives in the same folder. The <span class="code">archive/folder</span> is the path that the RDF is, relative to the sitemap.yml file.
			The <span class="code">num_docs_to_process_at_once</span> should probably initially be 1000, then adjusted as needed. If you know that there is
			no full text, or that the full text is particularly small, then you can increase the number. After you've run the archive, at the bottom of the *_compare_text.log file
			there are some statistics about the size of the full text. You can use those numbers to tune this. The larger the number, the faster the comparison runs,
			but it may also run out of memory. The correct number is hard to say, but the one that corresponds to 5 megs is probably ok.
		</p>
	</li>
	<li>Check the RDF in to SVN
		<p>
			The RDF should be saved in a logical folder in the RDF section of the SVN repository. Usually it will either be at a top level folder (just under
			<span class="code">~/index/rdf/</span> if it is a one-off archive, or a single subfolder deeper if it is part of a larger collection. After checking it in from your machine, then it
			must be checked out on the ARC Catalog staging server. <span class="code">ssh</span> onto the ARC Catalog staging machine, <span class="code">cd ~/index/rdf</span> to the rdf folder,
				and do <span class="code">svn up</span> to get all the latest RDF.
		</p>
	</li>
	<li>Debugging the RDF
		<p>
			The first time you run a particular set of RDF, you will probably want to do a test run to see if there are errors in the XML format, or missing
			required fields. The following command will run through the indexing process without actually saving anything so it runs fast and there is
			no risk:<br />
			<span class="code">rake solr_index:debug archive=archive_name</span><br />
			(Note: all commands should be run from <span class="code">cd ~/www/catalog</span> on the server.) This will create this file:
			<span class="code">log/archive_name_error.log</span>. Study that file to see if the RDF is acceptable and repeat this step as necessary.
		</p>
	</li>
	<li>Getting the (raw) full text (that is, "spidering")
		<p>
			Some archives contain all the data inside the RDF, either because they don't have full text, or because the full text was embedded in the RDF.
			Other archives, however, require getting the full text from a website. If the RDF contains the element <span class="code">&lt;collex:text&gt;</span>
			and that element contains a URL, then this step is required to get the data. Run this:<br />
			<span class="code">rake solr_index:spider_rdf_text archive=archive_name</span><br />
			That will leave all the text that it found in the folder <span class="code">~/index/rawtext/archive_name</span>. Unfortunately, this data
			is often dirty in that it will contain html or other things that should not be included. If you determine that the data is completely clean, it
			can be copied over to <span class="code">~/index/fulltext/archive_name</span> and the following step can be skipped.
		</p>
	</li>
	<li>Process the raw text
		<p>
			At the moment, this step needs to be done by hand because there is no telling what is messy about the data. Any text processing tool can
			be used, but so far, we've extended the rdf-indexer for each archive we've encountered. The final result, though, should be a set of files in
			<span class="code">~/index/fulltext/archive_name</span> that is completely clean of extraneous material and is ready to be put in
			the index.
		</p>
	</li>
	<li>Indexing an archive
		<p>
			After the RDF is debugged and the fulltext is retrieved and cleaned, then you can index, using this command:<br />
			<span class="code">rake solr_index:index archive=archive_name</span><br />
			This will leave a number of files in <span class="code">cd ~/www/catalog/log/</span> that start with <span class="code">archive_name</span>.
			Study these files to see if there are any errors.
		</p>
	</li>
	<li>Test manually
		<p>
			The indexing process only creates a test archive. It is not in the general index yet. To see the result of the indexing, you must open the
			staging version of Collex in a browser, log in, then go to the admin page and click "Temporarily use the testing index for searches". You
			can then see if the index is acceptable. At this point, you can go to <%= link_to "Archives", "/archives", { class: 'example_link' } %>
			to add the archive to the resource tree.
		</p>
	</li>
	<li>Deploying the index
		<p>
			There are actually three copies of the solr index: there is a copy on production, but in staging, there is both a mirror of the deployed index, and also the test index. The
			above steps only put the new content in the test index. There is a step to copy that new content to the regular staging index, and a step
			to copy that new content to production. It is important to copy the content to the staging index, because future reindexing steps will use
			that to run tests against. To copy to the staging index:<br />
			<span class="code">rake solr_index:merge_archive archive=archive_name</span><br />
			After that finishes, you should see the archive on the staging server.
		</p>
		<p>
			To deploy it to production, there are two steps, one to run on the indexing server, and one to run on the production server. Run this on the indexing server:<br />
			<span class="code">rake solr_index:package archive=archive_name</span><br />
			This will request the login password for getting on the server. Then, after that finishes, ssh into the production ARC Catalog, and run this:<br />
			<span class="code">rake solr_index:install archive=archive_name</span><br />
			If, after installing an archive, you decide you don't want it in the index after all, you can remove an archive with:<br />
			<span class="code">rake solr_index:remove archive=archive_name</span><br />
			Note that you will have to repeat the step of adding the archive to the resource tree for the production server.
		</p>
	</li>
</ol>
<h3>Refreshing Text</h3>
<p>Use these steps when you want to download the full text again (after you have been informed that the content has changed).</p>
<ol>
	<li>Spidering and processing
		<p>
			Use the same two procedures for spidering and processing above (steps #4 and #5).
		</p>
	</li>
	<li>Reindexing
		<p>
			Because there is already an index, we would like to make sure that only the parts of the index that we intended to change
			have, in fact, been changed. The following command both performs the indexing and the testing:<br />
			<span class="code">rake solr_index:index_and_test archive=archive_name</span><br />
			This will leave a number of files in <span class="code">cd ~/www/catalog/log/</span> that start with <span class="code">archive_name</span>.
			Any change to the index will be flagged as an error. If you understand what the change was (that is, any text that is updated will be flagged), then
			there is no problem, but if an unusual error appears, then you may have introduced a regression error and it should be explained or fixed.
		</p>
	</li>
	<li>Deploying
		<p>The same steps for testing and deploying that were outlined above (steps #7, #8) should be done for deploying. You will not have
		to add the archive to the resource tree a second time, though.
		</p>
	</li>
</ol>
<h3>Reindexing an Archive</h3>
<p>When the RDF is modified, but the full text doesn't have to be downloaded again.</p>
<ol>
	<li>Follow the steps for refreshing text, except that you don't have to do the spidering steps.</li>
</ol>
<h3>Reindexing the entire index</h3>
<p>There are a number of reasons that the entire index must be reindexed. These include: when the version of solr is updated, when
	a schema change in solr has been done, when a bug in the indexing process as been discovered, and when an improvement to the indexing
	process has been done.
</p>
<p>
	Because reindexing takes some time, it is recommended to test the reindexing on a small same of archives first, so that you know the work
	is debugged before reindexing the entire index.
</p>
<ol>
	<li>Snapshot of all log files
		<p>
			To make sure that no regression errors sneak in, and that the intended change actually happened, first store all the log files in <span class="code">cd ~/www/catalog/log/</span>
			somewhere else. They will all get recreated, and we want to run a diff program on them to make sure we understand what the indexing process did.
		</p>
	</li>
	<li>Create new batch files
		<p>
			Once in a while, it is good to regenerate the indexing batch files. They will get out of date when new archives are added. Use this to regenerate them:<br />
			<span class="code">rake solr_index:create_reindexing_task_list</span><br />
			This will create a number of files in <span class="code">cd ~/www/catalog/tmp/</span> that are a convenience to reindexing.
		</p>
	</li>
	<li>Restart solr
		<p>
			If there were schema changes, you must restart solr. This will vary depending on how solr has been set up, but on the servers, it will
			generally be by restarting the solr service, like this: <span class="code">sudo /sbin/service solr restart</span> On your local machine,
			it might be using the rake task: <span class="code">rake solr:restart</span>
		</p>
	</li>
	<li>Run reindexing batch files
		To reindex everything, run:<br />
		<p>
		<span class="code">tmp/batch_all.sh</span><br />
		To reindex some indexes, run one of the smaller batch files:<br />
		<span class="code">tmp/batch1.sh</span><br />
		You may also run any of the commands in those batch files independently.
		</p>
	</li>
	<li>Compare and study log files
		<p>
			After reindexing, use a diff tool to compare the new log files with the original files.
		</p>
	</li>
	<li>Merging
		<p>
			When you are satisfied with the test index, you need to merge all the archives into the staging index. This can be done with:<br />
			<span class="code">tmp/merge_all.sh</span><br />
			It is safest to stop solr, delete the entire resources index, and restart solr before running this, but if you are sure that there have been
			no archives deleted, this isn't necessary.
		</p>
	</li>
	<li>Deploying
		<p>You can deploy all the archives as above, but that will be really tedious for each archive. Instead, you should just copy the entire archive
			over to the production machine, then re-add the exhibits:<br />
			Remove all exhibits, since they will be the exhibits from the staging site.<br />
			<span class="code">rake solr_index:delete_exhibits</span><br />
			That will take a while. Then zip up the index and send it to the server.<br />
			<span class="code">rake solr_index:package_resources</span><br />
			That will take a while, too. Then ssh to the production server and install the new index.<br />
			<span class="code">rake solr:replace_resources</span><br />
			This will take a long time, too, and the production server will be down during part of that time. Then re-add the exhibits, by logging into
			each of the federation's Collex, and running:<br />
			<span class="code">rake indexing:all_exhibits</span><br />
		</p>
	</li>
</ol>
<table class="help">
	<tr>
		<th>Other Commands</th>
		<th>Description</th>
	</tr>
	<tr>
		<td>all tasks with archive parameter</td>
		<td>The archive parameter can be either a single archive, or a comma separated list of archives (for example: rossetti,bierce) Depending on the
			OS, you may have to put quotes around the archive list.</td>
	</tr>
	<tr>
		<td>rake&nbsp;ecco:typewright_enable</td>
		<td>Mark texts for typewright (param: file=/text/file/path/one/item/per/line) This is expecting a text file with a list of 10-digit numbers, one per line.
			The numbers are the document numbers for the objects that should be typewright enabled.</td>
	</tr>
	<tr>
		<td>rake&nbsp;solr:examine</td>
		<td>examine solr document, both in the regular index and the reindexing index (param: uri=XXX text=yes|no) If you have the URI
			of a document, then you can see all the info that is saved in solr about it. Because the text will quickly overwhelm all other fields, there
			is the option of suppressing it. This shows the results in both the regular index and the testing index (if they exist.)
		</td>
	</tr>
	<tr>
		<td>rake&nbsp;solr_index:remove_archive</td>
		<td>removes the archive from the resources index (param: archive=XXX,YYY)</td>
	</tr>
	<tr>
		<td>rake&nbsp;solr_index:archive_test</td>
		<td>Test one RDF archive (param: archive=XXX,YYY). This tests the archive without rebuilding it. Its only effect is to refresh the .log files.</td>
	</tr>
	<tr>
		<td>rake&nbsp;solr:backup</td>
		<td>Backup the solr index specified. Leave a tar file in the backups folder. (param: index=XXX) [i.e. index=archive_rossetti]</td>
	</tr>

</table>